{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of the Code\n",
    "\n",
    "This file contains two major sections that build and train reinforcement learning (RL) environments using a grammar-based approach. The goal in both sections is to have an RL agent learn to generate syntactically and semantically correct code. The first part targets generating GPU PTX code from a SASS-like grammar, while the second part simplifies the task to produce a single “MAC6” instruction.\n",
    "\n",
    "This work is inspired by the paper:\n",
    "\n",
    "> **CuAsmRL: Optimizing GPU SASS Schedules via Deep Reinforcement Learning**  \n",
    "> Guoliang He, Eiko Yoneki  \n",
    "> [arXiv:2501.08071](https://doi.org/10.48550/arXiv.2501.08071)  \n",
    ">  \n",
    "> *Large language models (LLMs) are remarked by their substantial computational requirements. To mitigate the cost, researchers develop specialized CUDA kernels, which often fuse several tensor operations to maximize the utilization of GPUs. However, those specialized kernels may still leave performance on the table as CUDA assembly experts show that manual optimization of GPU SASS schedules can lead to better performance. This work employs an automatic approach to optimize GPU SASS schedules using deep reinforcement learning by formulating an assembly game where RL agents iteratively mutate schedules to improve throughput.*\n",
    "\n",
    "---\n",
    "\n",
    "## Part 1: Grammar-Based RL Environment for PTX Code Generation\n",
    "\n",
    "### 1. Dynamic Grammar Creation\n",
    "- **Grammar Definition:**  \n",
    "  A function constructs a dynamic grammar with rules to generate code for a GPU kernel. The grammar includes nonterminals such as `Program`, `InstructionList`, `Instruction`, and specific instructions (`Load`, `MAC`, `Store`).\n",
    "- **Components:**  \n",
    "  - **Registers:** Defined as tokens $R0, R1, \\dots, R_{num\\_registers-1}$.\n",
    "  - **Memory References:** Tokens such as $[<A0\\_addr>], [<B0\\_addr>], [<C0\\_addr>]$, etc.\n",
    "- **Purpose:**  \n",
    "  To produce a complete program that will be transformed into SASS code and then into PTX.\n",
    "\n",
    "### 2. Parsing and Vocabulary Utilities\n",
    "- **Parsing Functions:**  \n",
    "  - `find_leftmost_nonterminal` locates the leftmost nonterminal in the current symbol list.\n",
    "  - `expansions_of` retrieves possible production expansions for a nonterminal.\n",
    "- **Vocabulary Building:**  \n",
    "  A function iterates through the grammar to build a set of terminal tokens, which are then sorted and indexed for observation purposes.\n",
    "\n",
    "### 3. SASS to PTX Conversion, Compilation, and GPU Execution\n",
    "- **SASS to PTX Conversion:**  \n",
    "  The function `sass_to_ptx` converts a SASS-like program to a PTX kernel by:\n",
    "  - Replacing placeholders (e.g., converting $<A0\\_addr>$ to $A0\\_ptr$).\n",
    "  - Mapping opcodes (e.g., replacing `LDG` with `ld.global.f32`).\n",
    "  - Wrapping the instructions with a PTX kernel header and footer.\n",
    "- **Compilation and Execution:**  \n",
    "  - The PTX code is compiled using `nvcc` into a CUDA binary (cubin file).\n",
    "  - A function loads the compiled module via PyCUDA, executes the kernel, and measures execution time.\n",
    "  - It compares the output against ground truth computed from 4x4 matrices.\n",
    "- **Matrix Loading:**  \n",
    "  A helper function loads (or generates) 3000 matrices (divided into three groups) and computes ground truth for a matrix multiply-accumulate operation.\n",
    "\n",
    "### 4. RL Environment for Grammar-Based Code Generation\n",
    "- **Environment Setup:**  \n",
    "  The `GrammarMultiLoadEnv` class inherits from Gym’s `Env` and allows the RL agent to select production rules from the grammar.\n",
    "- **Observation and Action Spaces:**  \n",
    "  - **Observations:**  \n",
    "    Represented as a fixed-length vector of token indices where nonterminals are given a special value.\n",
    "  - **Actions:**  \n",
    "    Consist of all valid $(nonterminal, \\ expansion\\ index)$ pairs.\n",
    "- **Reward Structure:**  \n",
    "  - Partial rewards are given for semantically correct instructions (e.g., a successful load or a valid MAC operation).\n",
    "  - Heavy penalties (e.g., $-500$) are applied if the final parse is incomplete or if the program fails to compile/execute correctly.\n",
    "- **Finalization:**  \n",
    "  Upon completion, the SASS program is converted to PTX, compiled, and executed on the GPU. The final reward is determined by execution time and correctness.\n",
    "\n",
    "### 5. Training with PPO\n",
    "- **RL Algorithm:**  \n",
    "  The training loop employs the Proximal Policy Optimization (PPO) algorithm from Stable Baselines3, wrapped in a vectorized environment (`DummyVecEnv`).\n",
    "- **Execution:**  \n",
    "  After training, several test episodes are executed to print out the total reward and debug information.\n",
    "\n",
    "---\n",
    "\n",
    "## Part 2: Simplified Environment for a Single MAC6 Instruction\n",
    "\n",
    "### 1. Simplified Grammar Definition\n",
    "- **Grammar Rules:**  \n",
    "  A reduced grammar is defined to generate only one valid instruction:\n",
    "  \n",
    "  $$\\text{Program} \\rightarrow \\text{MAC6 END}$$  \n",
    "  \n",
    "  $$\\text{MAC6} \\rightarrow \\text{\"MAC6\"}\\ \\text{Register},\\ \\text{Register},\\ \\text{Register},\\ \\text{Register},\\ \\text{Register},\\ \\text{Register};$$  \n",
    "  \n",
    "  $$\\text{Register} \\rightarrow \\{ R0, R1, R2, R3, R4, R5 \\}$$\n",
    "  \n",
    "- **Objective:**  \n",
    "  To ensure the RL agent generates a single instruction with six register operands, simplifying the output format.\n",
    "\n",
    "### 2. Environment Details\n",
    "- **Observation and Action Spaces:**  \n",
    "  Observations are fixed-length vectors of token indices and actions correspond to choices of production rule expansions.\n",
    "- **Program Finalization and Reward:**  \n",
    "  The environment finalizes the parse when the production is complete and checks:\n",
    "  - The program must begin with `MAC6` and end with `END`.\n",
    "  - The tokens must appear in the correct order, including commas and the semicolon.\n",
    "  - A positive reward (e.g., $+10$) is granted if the generated program is valid; otherwise, a penalty is applied.\n",
    "\n",
    "### 3. Training with PPO\n",
    "- **Simplified Training:**  \n",
    "  The PPO algorithm is employed in this simplified setting. The reduced complexity of the grammar and reward structure allows the RL agent to focus on learning the correct sequence to produce a valid `MAC6` instruction.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "- **Part 1:**  \n",
    "  Demonstrates a comprehensive setup where an RL agent learns to generate a complete PTX kernel by expanding a dynamic grammar, converting SASS to PTX, compiling, and running it on the GPU. Rewards are based on semantic correctness and execution performance.\n",
    "\n",
    "- **Part 2:**  \n",
    "  Reduces the task to generating a single valid `MAC6` instruction with six registers, greatly simplifying the grammar and reward design. This serves as a stepping stone to understand the core RL task without additional complexities.\n",
    "\n",
    "The design and approach of this code take inspiration from **CuAsmRL** by Guoliang He and Eiko Yoneki, which explores using deep reinforcement learning to optimize GPU SASS schedules. Just as CuAsmRL formulates an assembly game where the RL agent iteratively applies actions to improve kernel throughput, this code formulates a grammar-based game where the RL agent learns to generate correct code sequences. This work provides a foundational framework for integrating automated code generation and optimization techniques into compiler systems, aiming to reduce the manual effort typically required by CUDA assembly experts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will note that the file does not work exactly as expected. The outputs are saved to the .ptx file, but the loss is not what I expect. This implies that the program still needs more fixing, but the basic ideas is good!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded PTX program from agent_output.ptx\n",
      "Compilation failed with error:\n",
      "ptxas agent_output.ptx, line 40; fatal   : Parsing error near 'idx': syntax error\n",
      "ptxas fatal   : Ptx assembly aborted due to errors\n",
      "\n",
      "Loading matrices from big_mats.txt...\n",
      "Loaded 3000 matrices.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuModuleLoad failed: file not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 176\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# 4. Load the compiled cubin using PyCUDA.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpycuda\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdriver\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcuda\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcubin_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m kernel_func \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mget_function(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatrix_mmac\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# 5. Launch the kernel for each triple and measure total compute time.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m#    We assume each kernel execution computes D = A*B + C on a full 4x4 matrix.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m#    We use a block of (4,4,1) threads so that each thread computes one element.\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------------\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuModuleLoad failed: file not found"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import time\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit  # automatically initialize CUDA\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1. Read the RL agent's output PTX program from file.\n",
    "# ------------------------------------------------------------------------------\n",
    "ptx_filename = \"agent_output.ptx\"\n",
    "if not os.path.exists(ptx_filename):\n",
    "    # For demonstration, if the file doesn't exist, create a default PTX program.\n",
    "    default_ptx = r\"\"\"\n",
    ".version 7.0\n",
    ".target sm_75\n",
    ".address_size 64\n",
    "\n",
    ".visible .entry matrix_mmac(\n",
    "    .param .u64 A_ptr,\n",
    "    .param .u64 B_ptr,\n",
    "    .param .u64 C_ptr,\n",
    "    .param .u64 D_ptr\n",
    ")\n",
    "{\n",
    "    // Assume a 4x4 matrix multiply-accumulate: D = A*B + C.\n",
    "    // Each thread computes one element. We assume blockDim.x=4, blockDim.y=4.\n",
    "    .reg .s32 tid_x, tid_y, idx;\n",
    "    .reg .s32 i, j;\n",
    "    .reg .f32 a_val, b_val, c_val, prod, sum;\n",
    "    .reg .u64 A, B, C, D;\n",
    "\n",
    "    // Load parameters.\n",
    "    ld.param.u64 A, [A_ptr];\n",
    "    ld.param.u64 B, [B_ptr];\n",
    "    ld.param.u64 C, [C_ptr];\n",
    "    ld.param.u64 D, [D_ptr];\n",
    "\n",
    "    // Get thread indices (assume 4x4 block).\n",
    "    mov.u32 tid_x, %tid.x;\n",
    "    mov.u32 tid_y, %tid.y;\n",
    "    mov.s32 i, tid_y;\n",
    "    mov.s32 j, tid_x;\n",
    "\n",
    "    // Initialize sum = 0.\n",
    "    mov.f32 sum, 0f00000000;\n",
    "\n",
    "    // For k = 0 to 3, unrolled loop.\n",
    "    // k = 0:\n",
    "    mul.lo.s32 idx, i, 4;\n",
    "    add.s32 idx, idx, 0;\n",
    "    mul.lo.s32 idx, idx, 4;\n",
    "    ld.global.f32 a_val, [A + idx];\n",
    "    mul.lo.s32 idx, 0, 4;\n",
    "    add.s32 idx, idx, j;\n",
    "    mul.lo.s32 idx, idx, 4;\n",
    "    ld.global.f32 b_val, [B + idx];\n",
    "    mul.f32 prod, a_val, b_val;\n",
    "    add.f32 sum, sum, prod;\n",
    "\n",
    "    // k = 1:\n",
    "    mul.lo.s32 idx, i, 4;\n",
    "    add.s32 idx, idx, 1;\n",
    "    mul.lo.s32 idx, idx, 4;\n",
    "    ld.global.f32 a_val, [A + idx];\n",
    "    mul.lo.s32 idx, 1, 4;\n",
    "    add.s32 idx, idx, j;\n",
    "    mul.lo.s32 idx, idx, 4;\n",
    "    ld.global.f32 b_val, [B + idx];\n",
    "    mul.f32 prod, a_val, b_val;\n",
    "    add.f32 sum, sum, prod;\n",
    "\n",
    "    // k = 2:\n",
    "    mul.lo.s32 idx, i, 4;\n",
    "    add.s32 idx, idx, 2;\n",
    "    mul.lo.s32 idx, idx, 4;\n",
    "    ld.global.f32 a_val, [A + idx];\n",
    "    mul.lo.s32 idx, 2, 4;\n",
    "    add.s32 idx, idx, j;\n",
    "    mul.lo.s32 idx, idx, 4;\n",
    "    ld.global.f32 b_val, [B + idx];\n",
    "    mul.f32 prod, a_val, b_val;\n",
    "    add.f32 sum, sum, prod;\n",
    "\n",
    "    // k = 3:\n",
    "    mul.lo.s32 idx, i, 4;\n",
    "    add.s32 idx, idx, 3;\n",
    "    mul.lo.s32 idx, idx, 4;\n",
    "    ld.global.f32 a_val, [A + idx];\n",
    "    mul.lo.s32 idx, 3, 4;\n",
    "    add.s32 idx, idx, j;\n",
    "    mul.lo.s32 idx, idx, 4;\n",
    "    ld.global.f32 b_val, [B + idx];\n",
    "    mul.f32 prod, a_val, b_val;\n",
    "    add.f32 sum, sum, prod;\n",
    "\n",
    "    // Add C[i,j]:\n",
    "    mul.lo.s32 idx, i, 4;\n",
    "    add.s32 idx, idx, j;\n",
    "    mul.lo.s32 idx, idx, 4;\n",
    "    ld.global.f32 c_val, [C + idx];\n",
    "    add.f32 sum, sum, c_val;\n",
    "\n",
    "    // Store result:\n",
    "    st.global.f32 [D + idx], sum;\n",
    "\n",
    "    ret;\n",
    "}\n",
    "\"\"\"\n",
    "    with open(ptx_filename, \"w\") as f:\n",
    "        f.write(default_ptx)\n",
    "    print(\"Default PTX program written to\", ptx_filename)\n",
    "else:\n",
    "    print(\"Loaded PTX program from\", ptx_filename)\n",
    "\n",
    "with open(ptx_filename, \"r\") as f:\n",
    "    agent_ptx_program = f.read()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2. Compile the PTX program into a cubin file using nvcc.\n",
    "# ------------------------------------------------------------------------------\n",
    "cubin_filename = \"agent_output.cubin\"\n",
    "compile_cmd = [\"nvcc\", \"-arch=sm_75\", \"-cubin\", ptx_filename, \"-o\", cubin_filename]\n",
    "result = subprocess.run(compile_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "if result.returncode != 0:\n",
    "    print(\"Compilation failed with error:\")\n",
    "    print(result.stderr.decode())\n",
    "    exit(1)\n",
    "else:\n",
    "    print(\"Compilation succeeded. Cubin file generated:\", cubin_filename)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3. Generate or load 3000 random 4x4 matrices.\n",
    "#    We'll assume they are stored in a text file \"big_mats.txt\" with 3000 lines,\n",
    "#    each line containing 16 space-separated floats (representing a 4x4 matrix).\n",
    "#    The first 1000 lines are A matrices, the next 1000 are B, and the last 1000 are C.\n",
    "# ------------------------------------------------------------------------------\n",
    "n = 1000\n",
    "total_mats = 3 * n\n",
    "big_mats_file = \"big_mats.txt\"\n",
    "if not os.path.exists(big_mats_file):\n",
    "    print(f\"{big_mats_file} not found. Generating 3000 random 4x4 matrices...\")\n",
    "    mats = np.random.rand(total_mats, 4, 4).astype(np.float32)\n",
    "    with open(big_mats_file, \"w\") as f:\n",
    "        for mat in mats:\n",
    "            f.write(\" \".join(map(str, mat.flatten())) + \"\\n\")\n",
    "else:\n",
    "    print(f\"Loading matrices from {big_mats_file}...\")\n",
    "    mats = []\n",
    "    with open(big_mats_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            vals = list(map(float, line.strip().split()))\n",
    "            if len(vals) == 16:\n",
    "                mat = np.array(vals).reshape((4, 4)).astype(np.float32)\n",
    "                mats.append(mat)\n",
    "            if len(mats) >= total_mats:\n",
    "                break\n",
    "    mats = np.array(mats)\n",
    "    print(\"Loaded\", len(mats), \"matrices.\")\n",
    "\n",
    "# Partition matrices: first 1000 are A, next 1000 are B, last 1000 are C.\n",
    "A_mats = mats[0:n]\n",
    "B_mats = mats[n:2*n]\n",
    "C_mats = mats[2*n:3*n]\n",
    "\n",
    "# For demonstration, compute ground truth for the first triple (A^1, B^1, C^1) using numpy.\n",
    "A0 = A_mats[0]\n",
    "B0 = B_mats[0]\n",
    "C0 = C_mats[0]\n",
    "numpy_result = np.matmul(A0, B0) + C0\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4. Load the compiled cubin using PyCUDA.\n",
    "# ------------------------------------------------------------------------------\n",
    "import pycuda.driver as cuda\n",
    "module = cuda.module_from_file(cubin_filename)\n",
    "kernel_func = module.get_function(\"matrix_mmac\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 5. Launch the kernel for each triple and measure total compute time.\n",
    "#    We assume each kernel execution computes D = A*B + C on a full 4x4 matrix.\n",
    "#    We use a block of (4,4,1) threads so that each thread computes one element.\n",
    "# ------------------------------------------------------------------------------\n",
    "block_dim = (4, 4, 1)\n",
    "grid_dim = (1, 1)\n",
    "\n",
    "start_total = time.time()\n",
    "first_output = None  # to store output of the first triple\n",
    "\n",
    "for i in range(n):\n",
    "    A = A_mats[i]\n",
    "    B = B_mats[i]\n",
    "    C = C_mats[i]\n",
    "    D = np.zeros((4, 4), dtype=np.float32)\n",
    "    \n",
    "    # Flatten matrices to 1D arrays.\n",
    "    A_flat = A.flatten()\n",
    "    B_flat = B.flatten()\n",
    "    C_flat = C.flatten()\n",
    "    D_flat = D.flatten()\n",
    "    \n",
    "    # Allocate device memory.\n",
    "    A_gpu = cuda.mem_alloc(A_flat.nbytes)\n",
    "    B_gpu = cuda.mem_alloc(B_flat.nbytes)\n",
    "    C_gpu = cuda.mem_alloc(C_flat.nbytes)\n",
    "    D_gpu = cuda.mem_alloc(D_flat.nbytes)\n",
    "    \n",
    "    # Copy host data to device.\n",
    "    cuda.memcpy_htod(A_gpu, A_flat)\n",
    "    cuda.memcpy_htod(B_gpu, B_flat)\n",
    "    cuda.memcpy_htod(C_gpu, C_flat)\n",
    "    \n",
    "    # Launch the kernel.\n",
    "    kernel_func(A_gpu, B_gpu, C_gpu, D_gpu, block=block_dim, grid=grid_dim)\n",
    "    cuda.Context.synchronize()\n",
    "    \n",
    "    # Copy result back to host.\n",
    "    cuda.memcpy_dtoh(D_flat, D_gpu)\n",
    "    D_result = D_flat.reshape((4, 4))\n",
    "    \n",
    "    # Save the first triple's output.\n",
    "    if i == 0:\n",
    "        first_output = D_result\n",
    "\n",
    "end_total = time.time()\n",
    "total_compute_time = end_total - start_total\n",
    "average_time = total_compute_time / n\n",
    "\n",
    "print(\"\\n--- GPU Compute Time ---\")\n",
    "print(f\"Total GPU compute time for {n} triples: {total_compute_time:.6f} seconds\")\n",
    "print(f\"Average time per triple: {average_time:.6f} seconds\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 6. Display the first triple's matrices and compare results.\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n--- First Triple Matrices and Results ---\")\n",
    "print(\"Matrix A^1 (first A matrix):\")\n",
    "print(A0)\n",
    "print(\"\\nMatrix B^1 (first B matrix):\")\n",
    "print(B0)\n",
    "print(\"\\nMatrix C^1 (first C matrix):\")\n",
    "print(C0)\n",
    "print(\"\\nGPU Kernel Output D (first triple):\")\n",
    "print(first_output)\n",
    "print(\"\\nNumpy Computation (A^1 * B^1 + C^1):\")\n",
    "print(numpy_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max registers per block on this GPU: 65536\n",
      "Current Program:\n",
      "LDG R0 mem [ 0 ] ; LDG R1 mem [ 1 ] ; LDG R2 mem [ 2 ] ; MUL R0 , R1 -> R3 ; FADD R2 , R3 -> R2 ; MUL R0 , R1 -> R3 ; FADD R2 , R3 -> R2 ; MUL R0 , R1 -> R3 ; FADD R2 , R3 -> R2 ; STG R2 -> D ; END\n",
      "Reward: -16.003533840179443\n",
      "Info: {'exec_time': 0.0035338401794433594, 'error': 'Program valid'}\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Initialize PyCUDA and query the GPU for its maximum registers per block.\n",
    "import pycuda.driver as drv\n",
    "drv.init()\n",
    "device = drv.Device(0)\n",
    "# Query the maximum registers per block for this device.\n",
    "# (This value is typically large – e.g. 65536 for many NVIDIA GPUs.)\n",
    "max_registers = device.get_attribute(drv.device_attribute.MAX_REGISTERS_PER_BLOCK)\n",
    "print(f\"Max registers per block on this GPU: {max_registers}\")\n",
    "\n",
    "class FlexibleSassEnvDynamicRegisters(gym.Env):\n",
    "    \"\"\"\n",
    "    This environment lets an RL agent generate a complete SASS program (token-by-token)\n",
    "    for performing a matrix MAC operation. The program can interleave load, compute, and store\n",
    "    instructions arbitrarily, as long as the final output matches the expected result.\n",
    "    \n",
    "    At initialization, the environment queries the GPU for its maximum registers per block and\n",
    "    builds a vocabulary that includes tokens for registers R0 up to R(max_registers-1). This way,\n",
    "    the agent can choose any register available on the device.\n",
    "    \n",
    "    The intended computation is as follows (using 4×4 matrices):\n",
    "         result = C;  for each of N iterations: result = A * B + result\n",
    "    with A, B, and C taken from memory.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, required_mac_ops=1000, max_length=10000, matrix_file=\"matrices.txt\"):\n",
    "        super(FlexibleSassEnvDynamicRegisters, self).__init__()\n",
    "        self.required_mac_ops = required_mac_ops  # e.g., 1000 MAC operations\n",
    "        self.max_length = max_length             # Maximum program length (in tokens)\n",
    "        self.matrix_file = matrix_file\n",
    "        \n",
    "        # Query the GPU for the maximum registers available per block.\n",
    "        try:\n",
    "            self.max_registers = drv.Device(0).get_attribute(drv.device_attribute.MAX_REGISTERS_PER_BLOCK)\n",
    "        except Exception as e:\n",
    "            print(\"Error querying GPU registers. Defaulting to 256 registers.\")\n",
    "            self.max_registers = 256\n",
    "        \n",
    "        # Build dynamic register tokens: \"R0\", \"R1\", ..., \"R(max_registers-1)\"\n",
    "        register_tokens = [f\"R{i}\" for i in range(self.max_registers)]\n",
    "        \n",
    "        # Fixed tokens for opcodes, punctuation, etc.\n",
    "        fixed_tokens = [\n",
    "            \"PAD\",     # Padding token\n",
    "            \"LDG\",     # Load instruction\n",
    "            \"MUL\",     # Multiply instruction\n",
    "            \"FADD\",    # Floating-point add (for MAC)\n",
    "            \"STG\",     # Store instruction\n",
    "            \"D\",       # Destination token (for store)\n",
    "            \"mem\",     # Memory reference\n",
    "            \"[\",       # Left bracket\n",
    "            \"]\",       # Right bracket\n",
    "            \",\",       # Comma separator\n",
    "            \"->\",      # Arrow (for data flow)\n",
    "            \"END\",     # Program terminator\n",
    "            \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\",\n",
    "            \";\"        # Instruction separator\n",
    "        ]\n",
    "        \n",
    "        # The overall vocabulary is the fixed tokens plus all register tokens.\n",
    "        self.vocab = fixed_tokens + register_tokens\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.token_to_id = {token: idx for idx, token in enumerate(self.vocab)}\n",
    "        self.id_to_token = {idx: token for idx, token in enumerate(self.vocab)}\n",
    "        \n",
    "        # The RL agent outputs one token at a time (action space is discrete over the vocabulary).\n",
    "        self.action_space = spaces.Discrete(self.vocab_size)\n",
    "        # The observation is the entire program (as a sequence of token IDs) padded to a fixed length.\n",
    "        self.observation_space = spaces.Box(low=0, high=self.vocab_size - 1, shape=(self.max_length,), dtype=np.int32)\n",
    "        \n",
    "        # Load matrices from file. We expect at least 3000 randomly generated 4x4 matrices.\n",
    "        self.memory = self.load_matrices(self.matrix_file)\n",
    "        # For simulation, we use the first three matrices: A, B, and C.\n",
    "        self.A = self.memory[0]\n",
    "        self.B = self.memory[1]\n",
    "        self.C = self.memory[2]\n",
    "        self.ground_truth = self.compute_ground_truth()\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    def load_matrices(self, filename):\n",
    "        \"\"\"\n",
    "        Load 3000 4×4 matrices from a file.\n",
    "        If the file does not exist, generate random matrices and save them.\n",
    "        Each line should contain 16 whitespace-separated float values.\n",
    "        \"\"\"\n",
    "        matrices = []\n",
    "        if not os.path.exists(filename):\n",
    "            matrices = np.random.randn(3000, 4, 4).astype(np.float32)\n",
    "            np.savetxt(filename, matrices.reshape(3000, 16))\n",
    "        else:\n",
    "            with open(filename, \"r\") as f:\n",
    "                for line in f:\n",
    "                    values = list(map(float, line.strip().split()))\n",
    "                    if len(values) == 16:\n",
    "                        matrices.append(np.array(values).reshape((4, 4)).astype(np.float32))\n",
    "                    if len(matrices) >= 3000:\n",
    "                        break\n",
    "            matrices = np.array(matrices)\n",
    "        return matrices\n",
    "    \n",
    "    def compute_ground_truth(self):\n",
    "        \"\"\"\n",
    "        Compute the ground truth for the MAC operation:\n",
    "          result = C; for each iteration: result = A * B + result.\n",
    "        \"\"\"\n",
    "        result = self.C.copy()\n",
    "        for _ in range(self.required_mac_ops):\n",
    "            result = np.matmul(self.A, self.B) + result\n",
    "        return result\n",
    "    \n",
    "    def reset(self):\n",
    "        self.program_tokens = []  # List of token IDs generated so far.\n",
    "        self.start_time = time.time()  # Start timing when the program begins.\n",
    "        return self.get_observation()\n",
    "    \n",
    "    def step(self, action):\n",
    "        # Append the chosen token (if the program hasn't exceeded max_length).\n",
    "        if len(self.program_tokens) < self.max_length:\n",
    "            self.program_tokens.append(action)\n",
    "        else:\n",
    "            return self.get_observation(), -1000, True, {\"error\": \"Exceeded max program length\"}\n",
    "        \n",
    "        token = self.id_to_token[action]\n",
    "        if token == \"END\":\n",
    "            # When END is emitted, parse and simulate the program.\n",
    "            valid, cost, error, output = self.parse_and_simulate_program()\n",
    "            self.end_time = time.time()\n",
    "            exec_time = self.end_time - self.start_time  # Simulated total time.\n",
    "            # If the program is valid and output matches ground truth, reward is negative cost.\n",
    "            if valid and output is not None and np.allclose(output, self.ground_truth, atol=1e-4):\n",
    "                reward = -(cost + exec_time)\n",
    "            else:\n",
    "                reward = -1000  # Heavy penalty if invalid.\n",
    "            return self.get_observation(), reward, True, {\"exec_time\": exec_time, \"error\": error}\n",
    "        else:\n",
    "            return self.get_observation(), 0, False, {}\n",
    "    \n",
    "    def get_observation(self):\n",
    "        \"\"\"\n",
    "        Returns the current program as a fixed-length sequence of token IDs (padded with \"PAD\").\n",
    "        \"\"\"\n",
    "        obs = self.program_tokens.copy()\n",
    "        pad_id = self.token_to_id[\"PAD\"]\n",
    "        while len(obs) < self.max_length:\n",
    "            obs.append(pad_id)\n",
    "        return np.array(obs, dtype=np.int32)\n",
    "    \n",
    "    def parse_and_simulate_program(self):\n",
    "        \"\"\"\n",
    "        Parse the token sequence into instructions (splitting on \";\" tokens) and simulate execution.\n",
    "        The END token is treated as a terminator and is ignored in the simulation.\n",
    "        Allowed instructions include:\n",
    "          - LDG: Load a matrix from memory into a register.\n",
    "          - MUL: Multiply matrices from two registers, writing the result into a destination register.\n",
    "          - FADD: Add matrices from two registers.\n",
    "          - STG: Store a register’s contents into the destination memory D.\n",
    "        \"\"\"\n",
    "        # Convert token IDs back to tokens and remove \"PAD\" tokens.\n",
    "        tokens = [self.id_to_token[idx] for idx in self.program_tokens if self.id_to_token[idx] != \"PAD\"]\n",
    "        # Remove any standalone END tokens from the token stream.\n",
    "        tokens = [t for t in tokens if t != \"END\"]\n",
    "        # Split instructions by the \";\" separator.\n",
    "        instructions = []\n",
    "        current_instr = []\n",
    "        for t in tokens:\n",
    "            if t == \";\":\n",
    "                if current_instr:\n",
    "                    instructions.append(current_instr)\n",
    "                    current_instr = []\n",
    "            else:\n",
    "                current_instr.append(t)\n",
    "        if current_instr:\n",
    "            instructions.append(current_instr)\n",
    "        \n",
    "        registers = {}\n",
    "        total_cost = 0.0\n",
    "        mac_count = 0\n",
    "        error_message = \"\"\n",
    "        output_matrix = None\n",
    "        \n",
    "        cost_map = {\"LDG\": 1, \"MUL\": 2, \"FADD\": 2, \"STG\": 1}\n",
    "        \n",
    "        for instr in instructions:\n",
    "            if not instr:\n",
    "                continue\n",
    "            opcode = instr[0]\n",
    "            # Skip any END tokens if they accidentally appear in an instruction.\n",
    "            if opcode == \"END\":\n",
    "                continue\n",
    "            if opcode == \"LDG\":\n",
    "                if len(instr) != 6:\n",
    "                    error_message = f\"LDG instruction malformed: {instr}\"\n",
    "                    return False, total_cost, error_message, None\n",
    "                reg = instr[1]\n",
    "                if instr[2] != \"mem\" or instr[3] != \"[\" or instr[5] != \"]\":\n",
    "                    error_message = f\"LDG syntax error: {instr}\"\n",
    "                    return False, total_cost, error_message, None\n",
    "                mem_index = instr[4]\n",
    "                if mem_index not in [\"0\", \"1\", \"2\"]:\n",
    "                    error_message = f\"LDG invalid memory index: {mem_index}\"\n",
    "                    return False, total_cost, error_message, None\n",
    "                if mem_index == \"0\":\n",
    "                    registers[reg] = self.A.copy()\n",
    "                elif mem_index == \"1\":\n",
    "                    registers[reg] = self.B.copy()\n",
    "                elif mem_index == \"2\":\n",
    "                    registers[reg] = self.C.copy()\n",
    "                total_cost += cost_map[\"LDG\"]\n",
    "            elif opcode == \"MUL\":\n",
    "                if len(instr) != 6:\n",
    "                    error_message = f\"MUL instruction malformed: {instr}\"\n",
    "                    return False, total_cost, error_message, None\n",
    "                reg_src1 = instr[1]\n",
    "                reg_src2 = instr[3]\n",
    "                reg_dest = instr[5]\n",
    "                if reg_src1 not in registers or reg_src2 not in registers:\n",
    "                    error_message = f\"MUL uses undefined registers: {instr}\"\n",
    "                    return False, total_cost, error_message, None\n",
    "                try:\n",
    "                    registers[reg_dest] = np.matmul(registers[reg_src1], registers[reg_src2])\n",
    "                except Exception as e:\n",
    "                    error_message = f\"MUL failed: {e}\"\n",
    "                    return False, total_cost, error_message, None\n",
    "                total_cost += cost_map[\"MUL\"]\n",
    "            elif opcode == \"FADD\":\n",
    "                if len(instr) != 6:\n",
    "                    error_message = f\"FADD instruction malformed: {instr}\"\n",
    "                    return False, total_cost, error_message, None\n",
    "                reg_src1 = instr[1]\n",
    "                reg_src2 = instr[3]\n",
    "                reg_dest = instr[5]\n",
    "                if reg_src1 not in registers or reg_src2 not in registers:\n",
    "                    error_message = f\"FADD uses undefined registers: {instr}\"\n",
    "                    return False, total_cost, error_message, None\n",
    "                try:\n",
    "                    registers[reg_dest] = registers[reg_src1] + registers[reg_src2]\n",
    "                except Exception as e:\n",
    "                    error_message = f\"FADD failed: {e}\"\n",
    "                    return False, total_cost, error_message, None\n",
    "                total_cost += cost_map[\"FADD\"]\n",
    "                mac_count += 1\n",
    "            elif opcode == \"STG\":\n",
    "                if len(instr) != 4:\n",
    "                    error_message = f\"STG instruction malformed: {instr}\"\n",
    "                    return False, total_cost, error_message, None\n",
    "                reg_src = instr[1]\n",
    "                if instr[2] != \"->\" or instr[3] != \"D\":\n",
    "                    error_message = f\"STG syntax error: {instr}\"\n",
    "                    return False, total_cost, error_message, None\n",
    "                if reg_src not in registers:\n",
    "                    error_message = f\"STG uses undefined register: {instr}\"\n",
    "                    return False, total_cost, error_message, None\n",
    "                output_matrix = registers[reg_src].copy()\n",
    "                total_cost += cost_map[\"STG\"]\n",
    "            else:\n",
    "                error_message = f\"Unknown opcode: {opcode}\"\n",
    "                return False, total_cost, error_message, None\n",
    "        \n",
    "        if mac_count < self.required_mac_ops:\n",
    "            error_message = f\"Only {mac_count} MAC operations performed; expected {self.required_mac_ops}\"\n",
    "            return False, total_cost, error_message, None\n",
    "        \n",
    "        if output_matrix is None:\n",
    "            error_message = \"No STG instruction executed\"\n",
    "            return False, total_cost, error_message, None\n",
    "        \n",
    "        return True, total_cost, \"Program valid\", output_matrix\n",
    "    \n",
    "    def render(self, mode=\"human\"):\n",
    "        prog_tokens = [self.id_to_token[idx] for idx in self.program_tokens]\n",
    "        # Exclude PAD tokens for readability.\n",
    "        prog_str = \" \".join([tok for tok in prog_tokens if tok != \"PAD\"])\n",
    "        print(\"Current Program:\")\n",
    "        print(prog_str)\n",
    "\n",
    "# -------------------------------\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # For demonstration, we use a small number of MAC operations (e.g., 3) to keep the program short.\n",
    "    env = FlexibleSassEnvDynamicRegisters(required_mac_ops=3, max_length=500, matrix_file=\"matrices.txt\")\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    # Construct a valid program manually (the RL agent would learn to generate this).\n",
    "    program_tokens = []\n",
    "    \n",
    "    def add_instr(instr_tokens):\n",
    "        # Convert tokens to IDs and append a \";\" separator.\n",
    "        for t in instr_tokens:\n",
    "            program_tokens.append(env.token_to_id[t])\n",
    "        program_tokens.append(env.token_to_id[\";\"])\n",
    "    \n",
    "    # Sample program:\n",
    "    # Load operations (using registers from the dynamic vocabulary):\n",
    "    add_instr([\"LDG\", \"R0\", \"mem\", \"[\", \"0\", \"]\"])  # Load matrix A into R0\n",
    "    add_instr([\"LDG\", \"R1\", \"mem\", \"[\", \"1\", \"]\"])  # Load matrix B into R1\n",
    "    add_instr([\"LDG\", \"R2\", \"mem\", \"[\", \"2\", \"]\"])  # Load matrix C into R2\n",
    "    \n",
    "    # MAC operations: each MAC consists of a MUL followed by an FADD.\n",
    "    for _ in range(env.required_mac_ops):\n",
    "        add_instr([\"MUL\", \"R0\", \",\", \"R1\", \"->\", \"R3\"])  # Multiply A and B, store in R3\n",
    "        add_instr([\"FADD\", \"R2\", \",\", \"R3\", \"->\", \"R2\"])  # Add accumulator in R2 with R3\n",
    "    \n",
    "    # Store final result.\n",
    "    add_instr([\"STG\", \"R2\", \"->\", \"D\"])\n",
    "    # End program.\n",
    "    program_tokens.append(env.token_to_id[\"END\"])\n",
    "    program_tokens.append(env.token_to_id[\";\"])\n",
    "    \n",
    "    # Feed tokens into the environment one by one.\n",
    "    for token_id in program_tokens:\n",
    "        obs, reward, done, info = env.step(token_id)\n",
    "        if done:\n",
    "            break\n",
    "    env.render()\n",
    "    print(\"Reward:\", reward)\n",
    "    print(\"Info:\", info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryan/.local/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryan/.local/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 704  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 2    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 540           |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 7             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.7346264e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -8.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.92e+03      |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -4.43e-05     |\n",
      "|    value_loss           | 9.2e+03       |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 493            |\n",
      "|    iterations           | 3              |\n",
      "|    time_elapsed         | 12             |\n",
      "|    total_timesteps      | 6144           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -1.1641532e-10 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -8.04          |\n",
      "|    explained_variance   | nan            |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 2.86e+03       |\n",
      "|    n_updates            | 20             |\n",
      "|    policy_gradient_loss | 0              |\n",
      "|    value_loss           | 6.63e+03       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 495           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 16            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5969272e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -8.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.28e+03      |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -6.75e-05     |\n",
      "|    value_loss           | 5.11e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 445           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 22            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.1490725e-10 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -8.04         |\n",
      "|    explained_variance   | nan           |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+03      |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | 0             |\n",
      "|    value_loss           | 4.08e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 423          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.164758e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.04        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.43e+03     |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -2.24e-05    |\n",
      "|    value_loss           | 3.24e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 406           |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 35            |\n",
      "|    total_timesteps      | 14336         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.6170393e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -8.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.1e+03       |\n",
      "|    n_updates            | 60            |\n",
      "|    policy_gradient_loss | -2.91e-05     |\n",
      "|    value_loss           | 2.53e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 404          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.783498e-10 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.04        |\n",
      "|    explained_variance   | nan          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 821          |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | 0            |\n",
      "|    value_loss           | 1.92e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 400          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 45           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.802737e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.04        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 583          |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -3.23e-05    |\n",
      "|    value_loss           | 1.4e+03      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 407           |\n",
      "|    iterations           | 10            |\n",
      "|    time_elapsed         | 50            |\n",
      "|    total_timesteps      | 20480         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.6118234e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -8.04         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 386           |\n",
      "|    n_updates            | 90            |\n",
      "|    policy_gradient_loss | -3.39e-05     |\n",
      "|    value_loss           | 961           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 415         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 9.11532e-08 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.04       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 231         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -3.68e-05   |\n",
      "|    value_loss           | 609         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 420           |\n",
      "|    iterations           | 12            |\n",
      "|    time_elapsed         | 58            |\n",
      "|    total_timesteps      | 24576         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1152588e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -8.04         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 115           |\n",
      "|    n_updates            | 110           |\n",
      "|    policy_gradient_loss | -3.8e-05      |\n",
      "|    value_loss           | 339           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 413           |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 64            |\n",
      "|    total_timesteps      | 26624         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1350494e-09 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -8.04         |\n",
      "|    explained_variance   | nan           |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 39.7          |\n",
      "|    n_updates            | 120           |\n",
      "|    policy_gradient_loss | 0             |\n",
      "|    value_loss           | 148           |\n",
      "-------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 415      |\n",
      "|    iterations           | 14       |\n",
      "|    time_elapsed         | 68       |\n",
      "|    total_timesteps      | 28672    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -8.04    |\n",
      "|    explained_variance   | nan      |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 3.48     |\n",
      "|    n_updates            | 130      |\n",
      "|    policy_gradient_loss | 0        |\n",
      "|    value_loss           | 36.5     |\n",
      "--------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 418           |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 73            |\n",
      "|    total_timesteps      | 30720         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014021996 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -8.04         |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.0156       |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | -0.000788     |\n",
      "|    value_loss           | 0.967         |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 420         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001694376 |\n",
      "|    clip_fraction        | 0.00083     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.04       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.3e-06     |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00145    |\n",
      "|    value_loss           | 0.00098     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 420          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 82           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014574681 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.04        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.38e-08     |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00073     |\n",
      "|    value_loss           | 0.00049      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 413          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 89           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025295075 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -8.04        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.8e-08      |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.000743    |\n",
      "|    value_loss           | 0.00049      |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 408        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 95         |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00961796 |\n",
      "|    clip_fraction        | 0.0454     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.03      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.75e-06   |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.00166   |\n",
      "|    value_loss           | 0.000981   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033312332 |\n",
      "|    clip_fraction        | 0.373       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8          |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.19e-06    |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    value_loss           | 0.00245     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 399         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039823428 |\n",
      "|    clip_fraction        | 0.482       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.91       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0338     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00493    |\n",
      "|    value_loss           | 0.00245     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 397         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058570456 |\n",
      "|    clip_fraction        | 0.667       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.67       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.09e-06    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00912    |\n",
      "|    value_loss           | 0.0044      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 393         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052768044 |\n",
      "|    clip_fraction        | 0.492       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.36       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.82e-05    |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00788    |\n",
      "|    value_loss           | 0.00391     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 390        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 126        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04279362 |\n",
      "|    clip_fraction        | 0.62       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.27      |\n",
      "|    explained_variance   | 1.19e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0386    |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.0177    |\n",
      "|    value_loss           | 0.00833    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 391        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 130        |\n",
      "|    total_timesteps      | 51200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08311562 |\n",
      "|    clip_fraction        | 0.672      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -6.95      |\n",
      "|    explained_variance   | 1.19e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0405    |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.0188    |\n",
      "|    value_loss           | 0.0083     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 395        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 134        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15618752 |\n",
      "|    clip_fraction        | 0.75       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.64      |\n",
      "|    explained_variance   | 1.79e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0534    |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0248    |\n",
      "|    value_loss           | 0.0107     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 396        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 139        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19590448 |\n",
      "|    clip_fraction        | 0.759      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.48      |\n",
      "|    explained_variance   | 2.38e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0414    |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0437    |\n",
      "|    value_loss           | 0.0217     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 393        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 145        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14445558 |\n",
      "|    clip_fraction        | 0.874      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.28      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0728    |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0722    |\n",
      "|    value_loss           | 0.0435     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 396         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048381846 |\n",
      "|    clip_fraction        | 0.906       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.1        |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0717     |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.134      |\n",
      "|    value_loss           | 0.146       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 396         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042420506 |\n",
      "|    clip_fraction        | 0.899       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.99       |\n",
      "|    explained_variance   | -2.38e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0709     |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.141      |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 396         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 160         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039573498 |\n",
      "|    clip_fraction        | 0.859       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.89       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0493     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.144      |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 395        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 165        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03866468 |\n",
      "|    clip_fraction        | 0.83       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.72      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0318    |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.142     |\n",
      "|    value_loss           | 0.208      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 394         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 171         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033954367 |\n",
      "|    clip_fraction        | 0.788       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.39       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0352     |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.135      |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 395         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 176         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032924064 |\n",
      "|    clip_fraction        | 0.727       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0256     |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.124      |\n",
      "|    value_loss           | 0.241       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 397         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058315724 |\n",
      "|    clip_fraction        | 0.653       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 1.79e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00365    |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.1        |\n",
      "|    value_loss           | 0.25        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 399        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 184        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28090966 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.349     |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.078      |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0597    |\n",
      "|    value_loss           | 0.258      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 397          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 190          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018418244 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.116       |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.131        |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    value_loss           | 0.262        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 395          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 196          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013536367 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.084       |\n",
      "|    explained_variance   | 2.38e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.131        |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    value_loss           | 0.263        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 394           |\n",
      "|    iterations           | 39            |\n",
      "|    time_elapsed         | 202           |\n",
      "|    total_timesteps      | 79872         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00084995804 |\n",
      "|    clip_fraction        | 0.0085        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0634       |\n",
      "|    explained_variance   | 2.38e-07      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.132         |\n",
      "|    n_updates            | 380           |\n",
      "|    policy_gradient_loss | -0.00171      |\n",
      "|    value_loss           | 0.264         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 395           |\n",
      "|    iterations           | 40            |\n",
      "|    time_elapsed         | 207           |\n",
      "|    total_timesteps      | 81920         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00091761025 |\n",
      "|    clip_fraction        | 0.00718       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0491       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.135         |\n",
      "|    n_updates            | 390           |\n",
      "|    policy_gradient_loss | -0.00143      |\n",
      "|    value_loss           | 0.264         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 397          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 211          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003178746 |\n",
      "|    clip_fraction        | 0.00254      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0418      |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.132        |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.000535    |\n",
      "|    value_loss           | 0.265        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 396           |\n",
      "|    iterations           | 42            |\n",
      "|    time_elapsed         | 216           |\n",
      "|    total_timesteps      | 86016         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050309184 |\n",
      "|    clip_fraction        | 0.00342       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0341       |\n",
      "|    explained_variance   | 4.77e-07      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.132         |\n",
      "|    n_updates            | 410           |\n",
      "|    policy_gradient_loss | -0.000694     |\n",
      "|    value_loss           | 0.264         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 397           |\n",
      "|    iterations           | 43            |\n",
      "|    time_elapsed         | 221           |\n",
      "|    total_timesteps      | 88064         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044915805 |\n",
      "|    clip_fraction        | 0.00303       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0277       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.132         |\n",
      "|    n_updates            | 420           |\n",
      "|    policy_gradient_loss | -0.000641     |\n",
      "|    value_loss           | 0.265         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 398           |\n",
      "|    iterations           | 44            |\n",
      "|    time_elapsed         | 226           |\n",
      "|    total_timesteps      | 90112         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010856861 |\n",
      "|    clip_fraction        | 0.00083       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0251       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.132         |\n",
      "|    n_updates            | 430           |\n",
      "|    policy_gradient_loss | -0.000171     |\n",
      "|    value_loss           | 0.264         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 400          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 230          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002677168 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0218      |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.132        |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.000374    |\n",
      "|    value_loss           | 0.264        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 401           |\n",
      "|    iterations           | 46            |\n",
      "|    time_elapsed         | 234           |\n",
      "|    total_timesteps      | 94208         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021611038 |\n",
      "|    clip_fraction        | 0.00132       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0188       |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.132         |\n",
      "|    n_updates            | 450           |\n",
      "|    policy_gradient_loss | -0.000262     |\n",
      "|    value_loss           | 0.263         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 403          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 238          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009542698 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0135      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.128        |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.000625    |\n",
      "|    value_loss           | 0.264        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 405          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 242          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.568504e-05 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0123      |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.127        |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -9.01e-05    |\n",
      "|    value_loss           | 0.265        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 407           |\n",
      "|    iterations           | 49            |\n",
      "|    time_elapsed         | 246           |\n",
      "|    total_timesteps      | 100352        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014580993 |\n",
      "|    clip_fraction        | 0.00083       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0104       |\n",
      "|    explained_variance   | -2.38e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.131         |\n",
      "|    n_updates            | 480           |\n",
      "|    policy_gradient_loss | -0.000172     |\n",
      "|    value_loss           | 0.263         |\n",
      "-------------------------------------------\n",
      "Episode finished. Total Reward: -100.0 Info: {'error': 'InvalidExpansion', 'TimeLimit.truncated': False, 'terminal_observation': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)}\n",
      "Episode finished. Total Reward: -100.0 Info: {'error': 'InvalidExpansion', 'TimeLimit.truncated': False, 'terminal_observation': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)}\n",
      "Episode finished. Total Reward: -100.0 Info: {'error': 'InvalidExpansion', 'TimeLimit.truncated': False, 'terminal_observation': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from gym import spaces\n",
    "import subprocess\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit  # auto-initialize CUDA driver\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "###############################################################################\n",
    "# 1) DYNAMIC GRAMMAR CREATION (Example with permissive multi-load)\n",
    "###############################################################################\n",
    "\n",
    "def make_grammar(num_registers=100, num_mats_each=1000):\n",
    "    \"\"\"\n",
    "    Build a grammar with:\n",
    "      - Registers: R0..R(num_registers-1)\n",
    "      - MemoryRefs: [<A0_addr>]..[<A{num_mats_each-1}_addr>],\n",
    "                     [<B0_addr>]..[<B{num_mats_each-1}_addr>],\n",
    "                     [<C0_addr>]..[<C{num_mats_each-1}_addr>]\n",
    "    Grammar:\n",
    "      Program         -> InstructionList END\n",
    "      InstructionList -> InstructionList Instruction | Instruction\n",
    "      Instruction     -> Load | MAC | Store\n",
    "      Load            -> \"LDG\" Register \",\" MemoryRef \";\"\n",
    "      MAC             -> \"fma.rn.f32\" Register \",\" Register \",\" Register \";\"\n",
    "      Store           -> \"STG\" Register \",\" MemoryRef \";\"\n",
    "      END             -> \"END\"\n",
    "    \"\"\"\n",
    "    grammar = {}\n",
    "    grammar[\"Program\"] = [[\"InstructionList\", \"END\"]]\n",
    "    grammar[\"InstructionList\"] = [[\"InstructionList\", \"Instruction\"], [\"Instruction\"]]\n",
    "    grammar[\"Instruction\"] = [[\"Load\"], [\"MAC\"], [\"Store\"]]\n",
    "    grammar[\"Load\"] = [[\"LDG\", \"Register\", \",\", \"MemoryRef\", \";\"]]\n",
    "    grammar[\"MAC\"] = [[\"fma.rn.f32\", \"Register\", \",\", \"Register\", \",\", \"Register\", \";\"]]\n",
    "    grammar[\"Store\"] = [[\"STG\", \"Register\", \",\", \"MemoryRef\", \";\"]]\n",
    "    grammar[\"END\"] = [[\"END\"]]\n",
    "\n",
    "    # Build Register productions: R0 .. R{num_registers-1}\n",
    "    reg_prods = []\n",
    "    for r in range(num_registers):\n",
    "        reg_prods.append([f\"R{r}\"])\n",
    "    grammar[\"Register\"] = reg_prods\n",
    "\n",
    "    # Build MemoryRef productions: for A, B, and C placeholders.\n",
    "    mem_prods = []\n",
    "    for i in range(num_mats_each):\n",
    "        mem_prods.append([f\"[<A{i}_addr>]\"])\n",
    "    for i in range(num_mats_each):\n",
    "        mem_prods.append([f\"[<B{i}_addr>]\"])\n",
    "    for i in range(num_mats_each):\n",
    "        mem_prods.append([f\"[<C{i}_addr>]\"])\n",
    "    grammar[\"MemoryRef\"] = mem_prods\n",
    "\n",
    "    return grammar\n",
    "\n",
    "###############################################################################\n",
    "# 2) PARSING UTILITIES\n",
    "###############################################################################\n",
    "\n",
    "def find_leftmost_nonterminal(symbols, grammar):\n",
    "    for i, sym in enumerate(symbols):\n",
    "        if sym in grammar:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def expansions_of(nonterminal, grammar):\n",
    "    return grammar[nonterminal]\n",
    "\n",
    "###############################################################################\n",
    "# 3) Build Vocabulary from Grammar Terminals\n",
    "###############################################################################\n",
    "\n",
    "def build_vocab(grammar):\n",
    "    \"\"\"Return sorted list of all terminal tokens in the grammar.\"\"\"\n",
    "    terminals = set()\n",
    "    for key, expansions in grammar.items():\n",
    "        for expansion in expansions:\n",
    "            for token in expansion:\n",
    "                if token not in grammar:  # if not a nonterminal, it's a terminal\n",
    "                    terminals.add(token)\n",
    "    vocab = sorted(list(terminals))\n",
    "    return vocab\n",
    "\n",
    "###############################################################################\n",
    "# 4) SASS => PTX, Compilation, and GPU Run (Simplified)\n",
    "###############################################################################\n",
    "\n",
    "def sass_to_ptx(sass_str):\n",
    "    \"\"\"\n",
    "    Convert a SASS-like program into a PTX kernel.\n",
    "    - Replaces placeholders: e.g., <A0_addr> => A0_ptr.\n",
    "    - Converts opcodes: LDG -> ld.global.f32, STG -> st.global.f32.\n",
    "    - Wraps instructions in a PTX kernel header/footer.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    opcode_map = {\"LDG\": \"ld.global.f32\", \"STG\": \"st.global.f32\"}\n",
    "    lines = sass_str.strip().split(\"\\n\")\n",
    "    converted = []\n",
    "    for line in lines:\n",
    "        l = line.strip()\n",
    "        # Replace placeholders using regex\n",
    "        l = re.sub(r\"<(A|B|C)(\\d+)_addr>\", lambda m: f\"{m.group(1)}{m.group(2)}_ptr\", l)\n",
    "        # Replace opcodes if found at start\n",
    "        for k, v in opcode_map.items():\n",
    "            if l.startswith(k):\n",
    "                l = v + l[len(k):]\n",
    "        if not l.endswith(\";\"):\n",
    "            l += \";\"\n",
    "        converted.append(\"    \" + l)\n",
    "    header = \"\"\".version 7.0\n",
    ".target sm_75\n",
    ".address_size 64\n",
    "\n",
    ".visible .entry matrix_mmac(\n",
    "    .param .u64 A0_ptr, .param .u64 B0_ptr, .param .u64 C0_ptr, .param .u64 D0_ptr\n",
    ")\n",
    "{\n",
    "\"\"\"\n",
    "    footer = \"\"\"\n",
    "    ret;\n",
    "}\n",
    "\"\"\"\n",
    "    return header + \"\\n\".join(converted) + footer\n",
    "\n",
    "def compile_ptx(ptx_str, ptx_file=\"agent_kernel.ptx\", cubin_file=\"agent_kernel.cubin\"):\n",
    "    with open(ptx_file, \"w\") as f:\n",
    "        f.write(ptx_str)\n",
    "    cmd = [\"nvcc\", \"-arch=sm_75\", \"-cubin\", ptx_file, \"-o\", cubin_file]\n",
    "    r = subprocess.run(cmd, capture_output=True)\n",
    "    if r.returncode != 0:\n",
    "        return False, r.stderr.decode()\n",
    "    return True, \"\"\n",
    "\n",
    "def run_cubin(cubin_file):\n",
    "    \"\"\"\n",
    "    Load the compiled cubin and run the kernel.\n",
    "    For demonstration, we assume a kernel that processes a full 4x4 matrix.\n",
    "    In practice, you'd pass pointers for full matrices.\n",
    "    Here we allocate device memory for a single 4x4 matrix for A0, B0, C0 and output D0.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mod = cuda.module_from_file(cubin_file)\n",
    "        kernel_func = mod.get_function(\"matrix_mmac\")\n",
    "    except Exception as e:\n",
    "        return None, False, 0.0\n",
    "\n",
    "    # Create dummy 4x4 matrices for A0, B0, C0 (we expect the ground truth is A0*B0 + C0)\n",
    "    # For testing, we use the same matrices as provided by the environment.\n",
    "    # In a real system, these would come from the loaded 3000 matrices.\n",
    "    A0 = np.random.rand(4,4).astype(np.float32)\n",
    "    B0 = np.random.rand(4,4).astype(np.float32)\n",
    "    C0 = np.random.rand(4,4).astype(np.float32)\n",
    "    D0 = np.zeros((4,4), dtype=np.float32)\n",
    "\n",
    "    A0_flat = A0.flatten()\n",
    "    B0_flat = B0.flatten()\n",
    "    C0_flat = C0.flatten()\n",
    "    D0_flat = D0.flatten()\n",
    "\n",
    "    A0_gpu = cuda.mem_alloc(A0_flat.nbytes)\n",
    "    B0_gpu = cuda.mem_alloc(B0_flat.nbytes)\n",
    "    C0_gpu = cuda.mem_alloc(C0_flat.nbytes)\n",
    "    D0_gpu = cuda.mem_alloc(D0_flat.nbytes)\n",
    "\n",
    "    cuda.memcpy_htod(A0_gpu, A0_flat)\n",
    "    cuda.memcpy_htod(B0_gpu, B0_flat)\n",
    "    cuda.memcpy_htod(C0_gpu, C0_flat)\n",
    "\n",
    "    start = time.time()\n",
    "    kernel_func(A0_gpu, B0_gpu, C0_gpu, D0_gpu, block=(16,1,1), grid=(1,1))\n",
    "    cuda.Context.synchronize()\n",
    "    exec_time = time.time() - start\n",
    "\n",
    "    cuda.memcpy_dtoh(D0_flat, D0_gpu)\n",
    "    D0_result = D0_flat.reshape((4,4))\n",
    "    return D0_result, True, exec_time\n",
    "\n",
    "###############################################################################\n",
    "# 5) LOADING 3000 (4x4) MATRICES (1000 each for A, B, C)\n",
    "###############################################################################\n",
    "\n",
    "def load_big_matrices(n=1000, fname=\"big_mats.txt\"):\n",
    "    \"\"\"\n",
    "    Load 3000 4x4 matrices from file (if available) or generate them.\n",
    "    Returns three arrays: A_mats, B_mats, C_mats, each of shape (n, 4,4)\n",
    "    and ground truth computed as A0*B0 + C0.\n",
    "    \"\"\"\n",
    "    total = 3 * n\n",
    "    if not os.path.exists(fname):\n",
    "        mats = np.random.rand(total, 4,4).astype(np.float32)\n",
    "        with open(fname, \"w\") as f:\n",
    "            for mat in mats:\n",
    "                f.write(\" \".join(map(str, mat.flatten())) + \"\\n\")\n",
    "    else:\n",
    "        mats = []\n",
    "        with open(fname, \"r\") as f:\n",
    "            for line in f:\n",
    "                vals = list(map(float, line.strip().split()))\n",
    "                if len(vals) == 16:\n",
    "                    mats.append(np.array(vals).reshape((4,4)).astype(np.float32))\n",
    "                if len(mats) >= total:\n",
    "                    break\n",
    "        mats = np.array(mats)\n",
    "    A_mats = mats[0:n]\n",
    "    B_mats = mats[n:2*n]\n",
    "    C_mats = mats[2*n:3*n]\n",
    "    gt = np.matmul(A_mats[0], B_mats[0]) + C_mats[0]\n",
    "    return A_mats, B_mats, C_mats, gt\n",
    "\n",
    "###############################################################################\n",
    "# 6) GRAMMAR-BASED ENVIRONMENT WITH SEMANTIC CHECKS & PARTIAL REWARDS\n",
    "###############################################################################\n",
    "\n",
    "class GrammarMultiLoadEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Grammar-based environment where the agent selects grammar production rules.\n",
    "    - The grammar is permissive: loads, MAC, and stores may appear in any order.\n",
    "    - The observation is a fixed-length vector of token indices representing the current parse.\n",
    "    - Semantic checks are done on each completed instruction (partial reward).\n",
    "    - At termination, the SASS program is converted to PTX, compiled, run on the GPU,\n",
    "      and a final reward is assigned based on correctness and runtime.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_registers=100, n_mats_each=1000, max_expansions=30, max_obs_len=500, bigmat_file=\"big_mats.txt\"):\n",
    "        super().__init__()\n",
    "        self.grammar = make_grammar(num_registers, n_mats_each)\n",
    "        self.symbols = [\"Program\"]  # initial parse state\n",
    "        self.max_expansions = max_expansions\n",
    "        self.n_steps = 0\n",
    "        self.done_flag = False\n",
    "\n",
    "        # Build action space: flatten all (nonterminal, expansion_index) pairs.\n",
    "        self.actions_list = []\n",
    "        self.nt_index = {}\n",
    "        self._build_action_space()\n",
    "\n",
    "        # Build a vocabulary of terminal tokens from the grammar.\n",
    "        self.vocab = build_vocab(self.grammar)\n",
    "        self.token_to_idx = {token: i for i, token in enumerate(self.vocab)}\n",
    "        self.idx_to_token = {i: token for i, token in enumerate(self.vocab)}\n",
    "\n",
    "        # Define observation space as a fixed-length vector of token indices.\n",
    "        self.max_obs_len = max_obs_len\n",
    "        self.observation_space = spaces.Box(low=0, high=len(self.vocab)-1, shape=(self.max_obs_len,), dtype=np.int32)\n",
    "        self.action_space = spaces.Discrete(len(self.actions_list))\n",
    "\n",
    "        # Load big matrices and ground truth.\n",
    "        self.A_mats, self.B_mats, self.C_mats, self.ground_truth = load_big_matrices(n_mats_each, bigmat_file)\n",
    "\n",
    "        # For semantic checks, track register contents (which registers are loaded).\n",
    "        self.reg_contents = {}\n",
    "        for r in range(num_registers):\n",
    "            self.reg_contents[f\"R{r}\"] = False\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def _build_action_space(self):\n",
    "        idx_count = 0\n",
    "        for nt, expansions in self.grammar.items():\n",
    "            start_idx = idx_count\n",
    "            for i, _ in enumerate(expansions):\n",
    "                self.actions_list.append((nt, i))\n",
    "                idx_count += 1\n",
    "            self.nt_index[nt] = (start_idx, idx_count)\n",
    "\n",
    "    def _get_obs(self):\n",
    "        # Convert the current parse (self.symbols) into a sequence of token indices.\n",
    "        # If a symbol is nonterminal, assign a special index (we use 0).\n",
    "        obs_tokens = []\n",
    "        for sym in self.symbols:\n",
    "            if sym in self.grammar:\n",
    "                # nonterminal: assign 0 (or you can define a special token)\n",
    "                obs_tokens.append(0)\n",
    "            else:\n",
    "                obs_tokens.append(self.token_to_idx.get(sym, 0))\n",
    "        # Pad to max_obs_len.\n",
    "        if len(obs_tokens) < self.max_obs_len:\n",
    "            obs_tokens.extend([0] * (self.max_obs_len - len(obs_tokens)))\n",
    "        else:\n",
    "            obs_tokens = obs_tokens[:self.max_obs_len]\n",
    "        return np.array(obs_tokens, dtype=np.int32)\n",
    "\n",
    "    def reset(self):\n",
    "        self.symbols = [\"Program\"]\n",
    "        self.n_steps = 0\n",
    "        self.done_flag = False\n",
    "        for r in self.reg_contents:\n",
    "            self.reg_contents[r] = False\n",
    "        return self._get_obs()\n",
    "\n",
    "    def possible_actions_for(self, nt):\n",
    "        if nt not in self.nt_index:\n",
    "            return []\n",
    "        start, end = self.nt_index[nt]\n",
    "        return list(range(start, end))\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.done_flag:\n",
    "            return self._get_obs(), 0.0, True, {}\n",
    "        # Find leftmost nonterminal\n",
    "        idx = find_leftmost_nonterminal(self.symbols, self.grammar)\n",
    "        if idx < 0:\n",
    "            return self._finalize_parse()\n",
    "        current_nt = self.symbols[idx]\n",
    "        valid_actions = self.possible_actions_for(current_nt)\n",
    "        if action not in valid_actions:\n",
    "            self.done_flag = True\n",
    "            return self._get_obs(), -100.0, True, {\"error\": \"InvalidExpansion\"}\n",
    "        # Apply chosen expansion.\n",
    "        nt, exp_idx = self.actions_list[action]\n",
    "        expansion = self.grammar[nt][exp_idx]\n",
    "        self.symbols = self.symbols[:idx] + expansion + self.symbols[idx+1:]\n",
    "        self.n_steps += 1\n",
    "        # Partial semantic reward for last completed instruction.\n",
    "        partial_r = self._semantic_check_last_instruction()\n",
    "        if self.n_steps >= self.max_expansions:\n",
    "            return self._finalize_parse()[0], partial_r + self._finalize_parse()[1], True, {}\n",
    "        return self._get_obs(), partial_r, False, {}\n",
    "\n",
    "    def _semantic_check_last_instruction(self):\n",
    "        \"\"\"\n",
    "        Check the last complete instruction (ending with ';') for semantic validity.\n",
    "        Return a small positive reward if valid, negative if not.\n",
    "        For example:\n",
    "          - For a Load instruction, mark the target register as loaded (+0.1).\n",
    "          - For a MAC, check if the source registers are loaded (if yes, +0.2; else -0.2)\n",
    "          - For a Store, check if the register is loaded (+0.1)\n",
    "        \"\"\"\n",
    "        # Try to reconstruct instructions from self.symbols.\n",
    "        # We'll simply join symbols and split by \";\".\n",
    "        full_prog = \" \".join(self.symbols)\n",
    "        lines = full_prog.split(\";\")\n",
    "        if not lines:\n",
    "            return 0.0\n",
    "        last_line = lines[-2] if len(lines) >=2 else lines[-1]  # second last if last is empty\n",
    "        last_line = last_line.strip()\n",
    "        reward = 0.0\n",
    "        if last_line.startswith(\"LDG\"):\n",
    "            parts = last_line.split()\n",
    "            if len(parts) >= 2:\n",
    "                reg = parts[1].replace(\",\", \"\")\n",
    "                if reg in self.reg_contents:\n",
    "                    self.reg_contents[reg] = True\n",
    "                    reward += 0.1\n",
    "        elif last_line.startswith(\"fma.rn.f32\"):\n",
    "            parts = last_line.split()\n",
    "            if len(parts) >= 4:\n",
    "                dest = parts[1].replace(\",\", \"\")\n",
    "                src1 = parts[2].replace(\",\", \"\")\n",
    "                src2 = parts[3].replace(\",\", \"\")\n",
    "                if self.reg_contents.get(src1, False) and self.reg_contents.get(src2, False):\n",
    "                    if dest in self.reg_contents:\n",
    "                        self.reg_contents[dest] = True\n",
    "                    reward += 0.2\n",
    "                else:\n",
    "                    reward -= 0.2\n",
    "        elif last_line.startswith(\"STG\"):\n",
    "            parts = last_line.split()\n",
    "            if len(parts) >= 2:\n",
    "                reg = parts[1].replace(\",\", \"\")\n",
    "                if self.reg_contents.get(reg, False):\n",
    "                    reward += 0.1\n",
    "        return reward\n",
    "\n",
    "    def _finalize_parse(self):\n",
    "        self.done_flag = True\n",
    "        if find_leftmost_nonterminal(self.symbols, self.grammar) >= 0:\n",
    "            return self._get_obs(), -500.0, True, {\"error\": \"IncompleteParse\"}\n",
    "        # Build final SASS code (join terminals that end with ';' or are 'END')\n",
    "        lines = []\n",
    "        instr = []\n",
    "        for sym in self.symbols:\n",
    "            instr.append(sym)\n",
    "            if sym.endswith(\";\") or sym == \"END\":\n",
    "                lines.append(\" \".join(instr))\n",
    "                instr = []\n",
    "        sass_code = \"\\n\".join(lines)\n",
    "        ptx_str = sass_to_ptx(sass_code)\n",
    "        ok, err = compile_ptx_to_cubin(ptx_str)\n",
    "        if not ok:\n",
    "            return self._get_obs(), -500.0, True, {\"error\": \"CompileFail\", \"details\": err}\n",
    "        t0 = time.time()\n",
    "        Dmat, kernel_ok, kernel_time = run_cubin(\"agent_kernel.cubin\")\n",
    "        total_time = time.time() - t0\n",
    "        if (not kernel_ok) or (Dmat is None):\n",
    "            return self._get_obs(), -500.0, True, {\"error\": \"KernelFail\"}\n",
    "        correct = np.allclose(Dmat, self.ground_truth, atol=1e-3)\n",
    "        if not correct:\n",
    "            return self._get_obs(), -500.0, True, {\"error\": \"IncorrectResult\"}\n",
    "        final_reward = -total_time\n",
    "        return self._get_obs(), final_reward, True, {\n",
    "            \"exec_time\": total_time,\n",
    "            \"kernel_time\": kernel_time,\n",
    "            \"correct\": True\n",
    "        }\n",
    "\n",
    "###############################################################################\n",
    "# 7) TRAINING LOOP WITH PPO\n",
    "###############################################################################\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    def make_env():\n",
    "        return GrammarMultiLoadEnv(num_registers=100, n_mats_each=1000, max_expansions=30, max_obs_len=500, bigmat_file=\"big_mats.txt\")\n",
    "    env = DummyVecEnv([make_env])\n",
    "    model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "    model.learn(total_timesteps=100000)\n",
    "    obs = env.reset()\n",
    "    for _ in range(3):\n",
    "        done = [False]\n",
    "        total_reward = 0.0\n",
    "        while not done[0]:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            total_reward += reward[0]\n",
    "        print(\"Episode finished. Total Reward:\", total_reward, \"Info:\", info[0])\n",
    "        obs = env.reset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SASS program:\n",
      "\n",
      "\n",
      "Generated PTX program:\n",
      ".version 7.0\n",
      ".target sm_75\n",
      ".address_size 64\n",
      "\n",
      ".visible .entry matrix_mmac(\n",
      "    .param .u64 A0_ptr, .param .u64 B0_ptr, .param .u64 C0_ptr, .param .u64 D0_ptr\n",
      ")\n",
      "{\n",
      "    ;\n",
      "    ret;\n",
      "}\n",
      "\n",
      "\n",
      "PTX program written to 'generated_agent.ptx'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryan/.local/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# --- Assume the following have been defined or imported:\n",
    "# - GrammarMultiLoadEnv: your grammar-based environment\n",
    "# - sass_to_ptx(sass_str): function converting a SASS program (as a string) to PTX code.\n",
    "#\n",
    "# For this example, we assume these are available in the current scope.\n",
    "#\n",
    "# For example:\n",
    "# from my_rl_env_module import GrammarMultiLoadEnv, sass_to_ptx\n",
    "\n",
    "# Create the environment (using parameters from our production-level example)\n",
    "def make_env():\n",
    "    # Adjust parameters as needed; here we use 100 registers, 1000 matrices per type,\n",
    "    # a maximum of 50 expansions, and an observation length of 500 tokens.\n",
    "    return GrammarMultiLoadEnv(num_registers=100, n_mats_each=1000, max_expansions=50, max_obs_len=500, bigmat_file=\"big_mats.txt\")\n",
    "\n",
    "env = DummyVecEnv([make_env])\n",
    "\n",
    "# Load the trained model (assume it was saved as \"ppo_model.zip\")\n",
    "\n",
    "# Run one generation episode with the trained model\n",
    "obs = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    # Use deterministic actions for generation\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "\n",
    "# At this point, the environment’s underlying instance (the first one) has completed its parse.\n",
    "# Retrieve the final parse (list of symbols) from the underlying environment.\n",
    "final_parse = env.envs[0].symbols\n",
    "\n",
    "# Convert the final parse into a SASS program.\n",
    "# We assume that the SASS program is built by concatenating tokens into instructions,\n",
    "# breaking at tokens that end with \";\" or that equal \"END\".\n",
    "sass_lines = []\n",
    "current_instr = []\n",
    "for token in final_parse:\n",
    "    current_instr.append(token)\n",
    "    if token.endswith(\";\") or token == \"END\":\n",
    "        sass_lines.append(\" \".join(current_instr))\n",
    "        current_instr = []\n",
    "sass_program = \"\\n\".join(sass_lines)\n",
    "\n",
    "print(\"Generated SASS program:\")\n",
    "print(sass_program)\n",
    "\n",
    "# Convert the SASS program into a valid PTX program.\n",
    "ptx_program = sass_to_ptx(sass_program)\n",
    "\n",
    "print(\"\\nGenerated PTX program:\")\n",
    "print(ptx_program)\n",
    "\n",
    "# Optionally, write the PTX program to a file.\n",
    "with open(\"generated_agent.ptx\", \"w\") as f:\n",
    "    f.write(ptx_program)\n",
    "print(\"\\nPTX program written to 'generated_agent.ptx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 868  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 2    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 585          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020162982 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.2         |\n",
      "|    explained_variance   | -0.000834    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.86e+03     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0241      |\n",
      "|    value_loss           | 9.07e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 563         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014099638 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.18       |\n",
      "|    explained_variance   | -0.0134     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.82e+03    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0609     |\n",
      "|    value_loss           | 6.55e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 534         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041814514 |\n",
      "|    clip_fraction        | 0.526       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.06       |\n",
      "|    explained_variance   | 0.000736    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.23e+03    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0997     |\n",
      "|    value_loss           | 5.02e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 491        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 20         |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02411779 |\n",
      "|    clip_fraction        | 0.684      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.88      |\n",
      "|    explained_variance   | 0.00152    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.77e+03   |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.111     |\n",
      "|    value_loss           | 3.96e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 459         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025488384 |\n",
      "|    clip_fraction        | 0.681       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.00116     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.39e+03    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.105      |\n",
      "|    value_loss           | 3.11e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 432         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026408028 |\n",
      "|    clip_fraction        | 0.603       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | -7.86e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.05e+03    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0878     |\n",
      "|    value_loss           | 2.39e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 440         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032416403 |\n",
      "|    clip_fraction        | 0.496       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | -0.000367   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 745         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0697     |\n",
      "|    value_loss           | 1.78e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 430          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0126297735 |\n",
      "|    clip_fraction        | 0.265        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | -0.000879    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 508          |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0404      |\n",
      "|    value_loss           | 1.25e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 434         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027978932 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.93       |\n",
      "|    explained_variance   | -0.000657   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 309         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.048      |\n",
      "|    value_loss           | 811         |\n",
      "-----------------------------------------\n",
      "Episode finished. Total Reward: -100.0 Info: {'error': 'InvalidExpansion', 'TimeLimit.truncated': False, 'terminal_observation': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)}\n",
      "Episode finished. Total Reward: -100.0 Info: {'error': 'InvalidExpansion', 'TimeLimit.truncated': False, 'terminal_observation': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)}\n",
      "Episode finished. Total Reward: -100.0 Info: {'error': 'InvalidExpansion', 'TimeLimit.truncated': False, 'terminal_observation': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "###############################################################################\n",
    "# 1) SIMPLE GRAMMAR CREATION: Only a MAC6 instruction followed by END.\n",
    "###############################################################################\n",
    "\n",
    "def make_grammar():\n",
    "    \"\"\"\n",
    "    Defines a grammar where a valid program is:\n",
    "      Program -> MAC6 END\n",
    "      MAC6    -> \"MAC6\" Register \",\" Register \",\" Register \",\" Register \",\" Register \",\" Register \";\" \n",
    "      END     -> \"END\"\n",
    "      Register-> one of R0, R1, R2, R3, R4, R5\n",
    "    \"\"\"\n",
    "    grammar = {}\n",
    "    grammar[\"Program\"] = [[\"MAC6\", \"END\"]]\n",
    "    grammar[\"MAC6\"] = [[\n",
    "        \"MAC6\", \"Register\", \",\", \"Register\", \",\", \n",
    "        \"Register\", \",\", \"Register\", \",\", \"Register\", \",\", \"Register\", \";\"\n",
    "    ]]\n",
    "    grammar[\"END\"] = [[\"END\"]]\n",
    "    grammar[\"Register\"] = [[f\"R{i}\"] for i in range(6)]\n",
    "    return grammar\n",
    "\n",
    "###############################################################################\n",
    "# 2) PARSING UTILITIES\n",
    "###############################################################################\n",
    "\n",
    "def find_leftmost_nonterminal(symbols, grammar):\n",
    "    for i, sym in enumerate(symbols):\n",
    "        if sym in grammar:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "###############################################################################\n",
    "# 3) Build Vocabulary from Grammar Terminals\n",
    "###############################################################################\n",
    "\n",
    "def build_vocab(grammar):\n",
    "    \"\"\"Return sorted list of all terminal tokens in the grammar.\"\"\"\n",
    "    terminals = set()\n",
    "    for key, expansions in grammar.items():\n",
    "        for expansion in expansions:\n",
    "            for token in expansion:\n",
    "                if token not in grammar:  # terminal token\n",
    "                    terminals.add(token)\n",
    "    return sorted(list(terminals))\n",
    "\n",
    "###############################################################################\n",
    "# 4) SIMPLE GRAMMAR-BASED ENVIRONMENT\n",
    "###############################################################################\n",
    "\n",
    "class SimpleMAC6Env(gym.Env):\n",
    "    \"\"\"\n",
    "    A simplified grammar-based environment. The only valid program is:\n",
    "        MAC6 R?, R?, R?, R?, R?, R? ; END\n",
    "    where each R? is one of R0..R5.\n",
    "    \n",
    "    The agent selects production rules to expand the leftmost nonterminal.\n",
    "    A final reward is given if the program exactly matches the valid format.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_expansions=10, max_obs_len=30):\n",
    "        super().__init__()\n",
    "        self.grammar = make_grammar()\n",
    "        self.symbols = [\"Program\"]  # start symbol\n",
    "        self.max_expansions = max_expansions\n",
    "        self.n_steps = 0\n",
    "        self.done_flag = False\n",
    "        \n",
    "        # Build action space: flatten (nonterminal, expansion index) pairs.\n",
    "        self.actions_list = []\n",
    "        self.nt_index = {}\n",
    "        self._build_action_space()\n",
    "        \n",
    "        # Build vocabulary and token-index mappings.\n",
    "        self.vocab = build_vocab(self.grammar)\n",
    "        self.token_to_idx = {token: i for i, token in enumerate(self.vocab)}\n",
    "        self.idx_to_token = {i: token for i, token in enumerate(self.vocab)}\n",
    "        \n",
    "        # Observation: a fixed-length vector of token indices.\n",
    "        self.max_obs_len = max_obs_len\n",
    "        self.observation_space = spaces.Box(low=0, high=len(self.vocab)-1,\n",
    "                                            shape=(self.max_obs_len,), dtype=np.int32)\n",
    "        self.action_space = spaces.Discrete(len(self.actions_list))\n",
    "        \n",
    "        self.reset()\n",
    "\n",
    "    def _build_action_space(self):\n",
    "        idx_count = 0\n",
    "        for nt, expansions in self.grammar.items():\n",
    "            start_idx = idx_count\n",
    "            for i, _ in enumerate(expansions):\n",
    "                self.actions_list.append((nt, i))\n",
    "                idx_count += 1\n",
    "            self.nt_index[nt] = (start_idx, idx_count)\n",
    "\n",
    "    def _get_obs(self):\n",
    "        # Convert the current parse (list of symbols) into token indices.\n",
    "        obs_tokens = []\n",
    "        for sym in self.symbols:\n",
    "            # Use a special index for nonterminals (here we use 0, which corresponds to\n",
    "            # the first terminal in the sorted vocab; in practice you might reserve a unique index).\n",
    "            if sym in self.grammar:\n",
    "                obs_tokens.append(0)\n",
    "            else:\n",
    "                obs_tokens.append(self.token_to_idx.get(sym, 0))\n",
    "        # Pad or trim the observation.\n",
    "        if len(obs_tokens) < self.max_obs_len:\n",
    "            obs_tokens.extend([0] * (self.max_obs_len - len(obs_tokens)))\n",
    "        else:\n",
    "            obs_tokens = obs_tokens[:self.max_obs_len]\n",
    "        return np.array(obs_tokens, dtype=np.int32)\n",
    "\n",
    "    def reset(self):\n",
    "        self.symbols = [\"Program\"]\n",
    "        self.n_steps = 0\n",
    "        self.done_flag = False\n",
    "        return self._get_obs()\n",
    "\n",
    "    def possible_actions_for(self, nt):\n",
    "        if nt not in self.nt_index:\n",
    "            return []\n",
    "        start, end = self.nt_index[nt]\n",
    "        return list(range(start, end))\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.done_flag:\n",
    "            return self._get_obs(), 0.0, True, {}\n",
    "        # Find leftmost nonterminal.\n",
    "        idx = find_leftmost_nonterminal(self.symbols, self.grammar)\n",
    "        if idx < 0:\n",
    "            # Already complete.\n",
    "            return self._finalize_parse()\n",
    "        current_nt = self.symbols[idx]\n",
    "        valid_actions = self.possible_actions_for(current_nt)\n",
    "        if action not in valid_actions:\n",
    "            self.done_flag = True\n",
    "            return self._get_obs(), -100.0, True, {\"error\": \"InvalidExpansion\"}\n",
    "        # Apply the expansion.\n",
    "        nt, exp_idx = self.actions_list[action]\n",
    "        expansion = self.grammar[nt][exp_idx]\n",
    "        self.symbols = self.symbols[:idx] + expansion + self.symbols[idx+1:]\n",
    "        self.n_steps += 1\n",
    "        if self.n_steps >= self.max_expansions:\n",
    "            return self._finalize_parse()\n",
    "        # Check if the program is complete.\n",
    "        if find_leftmost_nonterminal(self.symbols, self.grammar) < 0:\n",
    "            return self._finalize_parse()\n",
    "        return self._get_obs(), 0.0, False, {}\n",
    "\n",
    "    def _finalize_parse(self):\n",
    "        self.done_flag = True\n",
    "        # The valid code is expected to be: MAC6 R?, R?, R?, R?, R?, R? ; END\n",
    "        expected_len = 1 + 6*2 + 1  # \"MAC6\" + six registers (each register preceded by a comma) + \"END\"\n",
    "        # For simplicity, we check that the sequence starts with \"MAC6\" and ends with \"END\"\n",
    "        if self.symbols[0] != \"MAC6\" or self.symbols[-1] != \"END\":\n",
    "            return self._get_obs(), -50.0, True, {\"error\": \"InvalidProgramFormat\"}\n",
    "        # Further, check that exactly one MAC6 production was used:\n",
    "        # The expected sequence is:\n",
    "        #   [\"MAC6\", Register, \",\", Register, \",\", Register, \",\", Register, \",\", Register, \",\", Register, \";\", \"END\"]\n",
    "        if len(self.symbols) != 14:\n",
    "            return self._get_obs(), -50.0, True, {\"error\": \"WrongNumberOfTokens\"}\n",
    "        # Check commas and semicolon positions.\n",
    "        if (self.symbols[2] != \",\" or self.symbols[4] != \",\" or \n",
    "            self.symbols[6] != \",\" or self.symbols[8] != \",\" or \n",
    "            self.symbols[10] != \",\" or self.symbols[12] != \";\"):\n",
    "            return self._get_obs(), -50.0, True, {\"error\": \"PunctuationError\"}\n",
    "        # If we reach here, the program is well formed.\n",
    "        # Provide a positive reward (for example, -runtime as a reward, here we simply use +10).\n",
    "        return self._get_obs(), 10.0, True, {\"info\": \"ValidMAC6Program\"}\n",
    "\n",
    "###############################################################################\n",
    "# 5) TRAINING LOOP WITH PPO\n",
    "###############################################################################\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    def make_env():\n",
    "        return SimpleMAC6Env(max_expansions=10, max_obs_len=30)\n",
    "    env = DummyVecEnv([make_env])\n",
    "    model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "    # Train for a reduced number of timesteps for demonstration.\n",
    "    model.learn(total_timesteps=20000)\n",
    "    \n",
    "    # Test a few episodes.\n",
    "    for ep in range(3):\n",
    "        obs = env.reset()\n",
    "        done = [False]\n",
    "        total_reward = 0.0\n",
    "        while not done[0]:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            total_reward += reward[0]\n",
    "        print(\"Episode finished. Total Reward:\", total_reward, \"Info:\", info[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
